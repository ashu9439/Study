#!/bin/sh

#
# Am I root?
#
uid=$(id -u)
if [ x$uid != x0 ]
then
    printf -v cmd_str '%q ' "$0" "$@"
    exec sudo su -c "$cmd_str"
    # I am root!
fi
#
#    Execute the following command ahead of time to
#    activate the crontab in Linux.
#    Once this is in place, everytime when an INDICATOR_FILE
#    file is present, this shell script is executed.
#
#    crontab -e
#    */5 * * * * /home/ec2-user/opcode/transform.sh
#

#
# Is there something to process?
#
INDICATOR_FILE='s3://ddoa-qa-dr-opcode/incoming/opcodeindicator.dat'
WORKING_DIRECTORY='/home/ec2-user/opcode/'
cd $WORKING_DIRECTORY

exists=$(aws s3 ls $INDICATOR_FILE)
if [ -z "$exists" ]; then
  echo "File" $INDICATOR_FILE
  echo "does not exist"
else
  #
  # We delete previous run files
  #
  rm -f run-*
  rm -f OA-TOY-OC*.xml
  rm -f OA-LEX-OC*.xml
  rm -f OA-TOY-OC*.xml.gz
  rm -f OA-LEX-OC*.xml.gz
  rm -f input-delta-toyota.xml
  rm -f input-full-toyota.xml
  rm -f input-delta-lexus.xml
  rm -f input-full-lexus.xml
  TIMEDATE=$(TZ=America/Chicago date +'%Y%m%d_%H%M%S')
  #
  # Define file locations
  #
  INCOMING_FILES='s3://ddoa-qa-dr-opcode/incoming/'
  OUTGOING_FILES='s3://ddoa-qa-dr-opcode/outgoing/'
  OUTPUT_FILES='s3://ddoa-qa-dr-opcode/output/'
  STAGE_DETAIL_TOY='s3://ddoa-qa-dr-opcode/stage/details/toy/'
  STAGE_DETAIL_LEX='s3://ddoa-qa-dr-opcode/stage/details/lex/'
  STAGE_FULL_TOY='s3://ddoa-qa-dr-opcode/stage/full/toy/'
  STAGE_FULL_LEX='s3://ddoa-qa-dr-opcode/stage/full/lex/'
  BACKLOG_FILES='s3://ddoa-qa-dr-opcode/backlog/'
  ARCHIVE_FILES='s3://ddoa-qa-dr-opcode/archive/'
  #
  # Glue process begins
  #
  aws s3 rm $STAGE_DETAIL_TOY --recursive --include "run-*"
  aws s3 rm $STAGE_DETAIL_LEX --recursive --include "run-*"
  aws s3 rm $STAGE_FULL_TOY --recursive --include "run-*"
  aws s3 rm $STAGE_FULL_LEX --recursive --include "run-*"
  echo "Run Glue job"
  aws glue start-job-run --job-name ddoa-qa-dr-opcode.py --region us-east-1
  echo "Delete indicator file"
  aws s3 rm $INDICATOR_FILE
  while [[ $(aws glue get-job-runs --job-name ddoa-qa-dr-opcode.py --max-items 1 --region us-east-1)  = *"RUNNING"* ]]
    do
    sleep 1m
  done
  if [[ $(aws glue get-job-runs --job-name ddoa-qa-dr-opcode.py --max-items 1 --region us-east-1) = *"FAILED"* ]]; then
    echo "Job failed. Moving files to Backlog folder"
    aws s3 mv $INCOMING_FILES"CatCodeDelta.csv" $BACKLOG_FILES"CatCodeDelta$TIMEDATE.csv"
    wait ${!}
    aws s3 mv $INCOMING_FILES"OpCodeDelta.csv" $BACKLOG_FILES"OpCodeDelta$TIMEDATE.csv"
    wait ${!}
    aws s3 mv $INCOMING_FILES"OpCodeDetailDeltaLexus.csv" $BACKLOG_FILES"OpCodeDetailDeltaLexus$TIMEDATE.csv"
    wait ${!}
    aws s3 mv $INCOMING_FILES"OpCodeDetailDeltaToyota.csv" $BACKLOG_FILES"OpCodeDetailDeltaToyota$TIMEDATE.csv"
    wait ${!}
    aws s3 mv $INCOMING_FILES"CatCodeFull.csv" $BACKLOG_FILES"CatCodeFull$TIMEDATE.csv"
    wait ${!}
    aws s3 mv $INCOMING_FILES"OpCodeDetailFullLexus.csv" $BACKLOG_FILES"OpCodeDetailFullLexus$TIMEDATE.csv"
    wait ${!}
    aws s3 mv $INCOMING_FILES"OpCodeDetailFullToyota.csv" $BACKLOG_FILES"OpCodeDetailFullToyota$TIMEDATE.csv"
    wait ${!}
    aws s3 mv $INCOMING_FILES"OpCodeFull.csv" $BACKLOG_FILES"OpCodeFull$TIMEDATE.csv"
    wait ${!}
    echo "Remove source files in S3"
    aws s3 rm $INCOMING_FILES  --recursive
    exit 0
  fi
  echo "Archive csv files"
  aws s3 mv $INCOMING_FILES"CatCodeDelta.csv" $ARCHIVE_FILES"CatCodeDelta$TIMEDATE.csv"
  wait ${!}
  aws s3 mv $INCOMING_FILES"OpCodeDelta.csv" $ARCHIVE_FILES"OpCodeDelta$TIMEDATE.csv"
  wait ${!}
  aws s3 mv $INCOMING_FILES"OpCodeDetailDeltaLexus.csv" $ARCHIVE_FILES"OpCodeDetailDeltaLexus$TIMEDATE.csv"
  wait ${!}
  aws s3 mv $INCOMING_FILES"OpCodeDetailDeltaToyota.csv" $ARCHIVE_FILES"OpCodeDetailDeltaToyota$TIMEDATE.csv"
  wait ${!}
  aws s3 mv $INCOMING_FILES"CatCodeFull.csv" $ARCHIVE_FILES"CatCodeFull$TIMEDATE.csv"
  wait ${!}
  aws s3 mv $INCOMING_FILES"OpCodeDetailFullLexus.csv" $ARCHIVE_FILES"OpCodeDetailFullLexus$TIMEDATE.csv"
  wait ${!}
  aws s3 mv $INCOMING_FILES"OpCodeDetailFullToyota.csv" $ARCHIVE_FILES"OpCodeDetailFullToyota$TIMEDATE.csv"
  wait ${!}
  aws s3 mv $INCOMING_FILES"OpCodeFull.csv" $ARCHIVE_FILES"OpCodeFull$TIMEDATE.csv"
  wait ${!}
  echo "Remove source files in S3"
  aws s3 rm $INCOMING_FILES  --recursive
  #
  # We define file names
  #
  echo "Operation Code Deltas Toyota"
  OCDT='OA-TOY-OCD_'$TIMEDATE'.xml'
  echo "Operation Code Deltas Lexus"
  OCDL='OA-LEX-OCD_'$TIMEDATE'.xml'
  echo "Operation Code Full Toyota"
  OCFT='OA-TOY-OCF_'$TIMEDATE'.xml'
  echo "Operation Code Full Lexus"
  OCFL='OA-LEX-OCF_'$TIMEDATE'.xml'
  #
  # We process OpCode deltas Toyota
  #
  echo "Copy Toyota's detail file from S3 to EC2"
  aws s3 cp $STAGE_DETAIL_TOY $WORKING_DIRECTORY --recursive --exclude "*" --include "run-*"
  echo "Rename the file to input-details-toyota.xml in EC2"
  mv run-* input-delta-toyota.xml
  echo "Execute XSLT transformation for Toyota deltas"
  #xsltproc --output $OCDT showLaborOperations-TY.xsl input-delta-toyota.xml
  java -Xms8000m -jar saxon9he.jar -t -tree:tinyc -s:input-delta-toyota.xml -xsl:showLaborOperations-TY.xsl -o:stage-delta-toyota.xml
  wait ${!}
  java -Xms8000m -jar saxon9he.jar -t -tree:tinyc -s:stage-delta-toyota.xml -xsl:removeemptytag.xsl -o:$OCDT
  wait ${!}
  rm stage-delta-toyota.xml
  #
  # We process OpCode deltas Lexus
  #
  echo "Copy Lexus' deltas file from S3 to EC2"
  aws s3 cp $STAGE_DETAIL_LEX $WORKING_DIRECTORY --recursive --exclude "*" --include "run-*"
  echo "Rename the file to input-delta-lexus in EC2"
  mv run-* input-delta-lexus.xml
  echo "Execute XSLT transformation for Lexus deltas"
  #xsltproc --output $OCDL showLaborOperations-LX.xsl input-delta-lexus.xml
  java -Xms8000m -jar saxon9he.jar -t -tree:tinyc -s:input-delta-lexus.xml -xsl:showLaborOperations-LX.xsl -o:stage-delta-lexus.xml
  wait ${!}
  java -Xms8000m -jar saxon9he.jar -t -tree:tinyc -s:stage-delta-lexus.xml -xsl:removeemptytag.xsl -o:$OCDL
  wait ${!}
  rm stage-delta-lexus.xml
  #
  # We process OpCode full Lexus
  #
  echo "Copy Lexus' full file from S3 to EC2"
  aws s3 cp $STAGE_FULL_LEX $WORKING_DIRECTORY --recursive --exclude "*" --include "run-*"
  echo "Rename the file to input-full-lexus in EC2"
  mv run-* input-full-lexus.xml
  echo "Execute XSLT transformation for Lexus deltas"
  #xsltproc --output $OCFL showLaborOperations-LX.xsl input-full-lexus.xml
  java -Xms9000m -jar saxon9he.jar -t -tree:tinyc -s:input-full-lexus.xml -xsl:showLaborOperations-LX.xsl -o:stage-full-lexus.xml
  wait ${!}
  java -Xms9000m -jar saxon9he.jar -t -tree:tinyc -s:stage-full-lexus.xml -xsl:removeemptytag.xsl -o:$OCFL
  wait ${!}
  rm stage-full-lexus.xml
  #
  # We process OpCode full Toyota
  #
  echo "Copy Toyota's full file from S3 to EC2"
  aws s3 cp $STAGE_FULL_TOY $WORKING_DIRECTORY --recursive --exclude "*" --include "run-*"
  echo "Rename the file to input-full-toyota.xml in EC2"
  mv run-* input-full-toyota.xml
  echo "Execute XSLT transformation for Toyota full"
  java -Xms9000m -jar saxon9he.jar -t -tree:tinyc -s:input-full-toyota.xml -xsl:showLaborOperations-TY.xsl -o:stage-full-toyota.xml
  wait ${!}
  java -Xms9000m -jar saxon9he.jar -t -tree:tinyc -s:stage-full-toyota.xml -xsl:removeemptytag.xsl -o:$OCFT
  wait ${!}
  rm stage-full-toyota.xml
  #
  # Process zipping the files up.
  #
  echo "Zip the files up"
  #tar -czf $OCDT.gz $OCDT
  FILESIZE=$(stat -c%s $OCDT)
  if ((FILESIZE > 0 ));then
  gzip -c $OCDT > $OCDT.gz
  aws s3 cp $OCDT.gz $OUTGOING_FILES --content-type application/x-gzip
  wait ${!}
  aws s3 cp $OCDT.gz $OUTPUT_FILES --content-type application/x-gzip
   wait ${!}
  fi

  FILESIZE=$(stat -c%s $OCDL)
  if ((FILESIZE > 0 ));then
  gzip -c $OCDL > $OCDL.gz
  wait ${!}
  aws s3 cp $OCDL.gz $OUTGOING_FILES --content-type application/x-gzip
  wait ${!}
  aws s3 cp $OCDL.gz $OUTPUT_FILES --content-type application/x-gzip
  wait ${!}
  fi

  FILESIZE=$(stat -c%s $OCFT)
  if ((FILESIZE > 0 ));then
  gzip -c $OCFT > $OCFT.gz
  wait ${!}
  aws s3 cp $OCFT.gz $OUTGOING_FILES --content-type application/x-gzip
  wait ${!}
  aws s3 cp $OCFT.gz $OUTPUT_FILES --content-type application/x-gzip
  wait ${!}
  fi

  FILESIZE=$(stat -c%s $OCFL)
  if ((FILESIZE > 0 ));then
  gzip -c $OCFL > $OCFL.gz
  wait ${!}
  aws s3 cp $OCFL.gz $OUTGOING_FILES --content-type application/x-gzip
  wait ${!}
  aws s3 cp $OCFL.gz $OUTPUT_FILES --content-type application/x-gzip
  wait ${!}
  fi

#   sshpass -p "XSW@3edc" sftp ddoa_q@10.85.36.101 <<END_SCRIPT
#    cd ddoa/download/LaborOperations/TY/5.4.4.0.0
#    put $OCDT.gz
#    put $OCFT.gz
#    cd /
#    cd /home/ddoa/ddoa_q/ddoa/download/LaborOperations/LX/5.4.4.0.0
#    put $OCDL.gz
#    put $OCFL.gz
#    quit
# END_SCRIPT


  echo "Notify Lambda that the OpCode processed file is ready"
  sleep 1m
  md5sum $OCDT.gz > opcode-files-ready.dat
  wait ${!}
  md5sum $OCDL.gz >> opcode-files-ready.dat
  wait ${!}
  md5sum $OCFT.gz >> opcode-files-ready.dat
  wait ${!}
  md5sum $OCFL.gz >> opcode-files-ready.dat
  wait ${!}
  sed -i 's/  /,/g' opcode-files-ready.dat
  #sed -i 's/.gz//g' opcode-files-ready.dat
  aws s3 cp opcode-files-ready.dat $OUTGOING_FILES
  wait ${!}
fi
#rm -f opcode-files-ready.dat
echo 'End of OpCode process'
exit
